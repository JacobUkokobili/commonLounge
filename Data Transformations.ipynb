{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E6I8Qb4K0xo"
   },
   "source": [
    "As part of data cleaning, we often need to transform data into a more usable form for data science and machine learning.\n",
    "\n",
    "We will start by discussing data transformation methods for numerical variables first, and then move on to categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3zK5sGJKlK1"
   },
   "source": [
    "Numerical Variables\n",
    "Let's address numerical variable transformations first.\n",
    "\n",
    "Skewed distributions: Log transformation\n",
    "Often in the real-world, we encounter exponential distributions. Exponential distributions are extremely skewed, and many machine learning models don't work well with extremely skewed data.\n",
    "\n",
    "One way to fix this, is to take the log of all values for that variable. In our dataset, the variables Entrance Rank and Family Income have skewed distributions. Let's verify that using a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiXC90lPKyQO"
   },
   "outputs": [],
   "source": [
    "plt.subplots_adjust(hspace=1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['Entrance Rank'], ec='black', bins=20)\n",
    "plt.title(\"Entrance Rank\")\n",
    " \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['Family Income'], ec='black', bins=20)\n",
    "plt.title('Family Income')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiOj2JFWLMPV"
   },
   "source": [
    "Performing the log transformation on these variables reduces the skewness. We'll use the np.log() function do to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HxSWuPgLEKJ"
   },
   "outputs": [],
   "source": [
    "df['Family Income'] = np.log(df['Family Income'])\n",
    "df['Entrance Rank'] = np.log(df['Entrance Rank'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFby5-EsLZeB"
   },
   "source": [
    "Notice the changed values of both variables.\n",
    "\n",
    "Let's visualize the new distribution of by plotting histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjsZksKeLae7"
   },
   "outputs": [],
   "source": [
    "plt.subplots_adjust(hspace=1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['Entrance Rank'], ec='black', bins=20)\n",
    "plt.title(\"Entrance Rank\")\n",
    " \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['Family Income'], ec='black', bins=20)\n",
    "plt.title('Family Income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgfVgVQBLj0w"
   },
   "source": [
    "Now, our data for these two variables resembles the normal distribution, which is ideal for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SAPSqhpnL-ap"
   },
   "source": [
    "Data Re-scaling\n",
    "Many algorithms require numerical data to be re-scaled before fitting the model. Here are some reasons why data re-scaling is important:\n",
    "\n",
    "It makes the results meaningful (especially for distance based algorithms).\n",
    "It ensures variables with high magnitude don't dominate the data analysis, models and predictions.\n",
    "Many machine learning algorithms converge faster on re-scaled data.\n",
    "The two most common methods for re-scaling are normalization and standardization. Let's see them one by one.\n",
    "\n",
    "Normalization\n",
    "In normalization, the data is re-scaled to be in the range 0 to 1. So after rescaling, the minimum value of the variable is 0 and maximum value is 1.\n",
    "\n",
    "The formula for normalizing is:\n",
    "$\n",
    "x\n",
    "n\n",
    "e\n",
    "w\n",
    "=\n",
    "x\n",
    "−\n",
    "m\n",
    "i\n",
    "n\n",
    "/\n",
    "m\n",
    "a\n",
    "x\n",
    "−\n",
    "m\n",
    "i\n",
    "n$\n",
    "\n",
    "Before we do normalization, let's make a copy of our data and take a look at the first few rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRyi30rQMh9J"
   },
   "outputs": [],
   "source": [
    "df_temp = df.copy()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpZ8oQy8MsTJ"
   },
   "source": [
    "Now, we can perform the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8qxYb5gMoDa"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Normalization of numeric variables - not to be implemented on df, so using df_temp\n",
    "df_temp.loc[:,numeric_labels] = preprocessing.MinMaxScaler().fit_transform(df_temp.loc[:,numeric_labels])\n",
    "# first five observations\n",
    "df_temp.iloc[:,:-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5P9nYagM3S4"
   },
   "source": [
    "Variables having different scales and units can be easily compared after Normalization. Let's plot the histogram for visualization of normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0Ea6FIuM39B"
   },
   "outputs": [],
   "source": [
    "plt.subplots_adjust(hspace=1)\n",
    " \n",
    "plt.subplot(3, 2, 1)\n",
    "plt.hist(df_temp['Entrance Rank'], ec='black', bins=20)\n",
    "plt.title(\"Entrance Rank\")\n",
    " \n",
    "plt.subplot(3, 2, 2)\n",
    "plt.hist(df_temp['Matriculation'], ec='black', bins=20)\n",
    "plt.title('Matriculation')\n",
    " \n",
    "plt.subplot(3, 2, 3)\n",
    "plt.hist(df_temp['Family Income'], ec='black', bins=20)\n",
    "plt.title('Family Income')\n",
    " \n",
    "plt.subplot(3, 2, 4)\n",
    "plt.hist(df_temp['Physics'], ec='black', bins=20)\n",
    "plt.title('Physics')\n",
    " \n",
    "plt.subplot(3, 2, 5)\n",
    "plt.hist(df_temp['Chemistry'], ec='black', bins=20)\n",
    "plt.title('Chemistry')\n",
    " \n",
    "plt.subplot(3, 2, 6)\n",
    "plt.hist(df_temp['Maths'], ec='black', bins=20)\n",
    "plt.title('Maths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "issaPMfoNDjj"
   },
   "source": [
    "All numerical variables has a range of ( 0, 1 )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0TyVHx6NKLk"
   },
   "source": [
    "Standardization\n",
    "Here the data (x) is re-scaled so that mean becomes 0 (μ = 0) and standard deviation becomes 1 (σ = 1). The standardization formula is:\n",
    "\n",
    "$\n",
    "x\n",
    "n\n",
    "e\n",
    "w\n",
    "=\n",
    "x\n",
    "−\n",
    "μ\n",
    "/\n",
    "σ\n",
    "$\n",
    "\n",
    "Consider our data above with Entrance Rank, Family Income and marks of various subjects, which are having different scales and units. We can compare these features and use them in our models once we have standardized them. The results obtained will be more accurate for standardized data.\n",
    "\n",
    "See the python code for standardizing numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIzl4og6NC0s"
   },
   "outputs": [],
   "source": [
    "#standardizing numerical variables\n",
    "from sklearn import preprocessing\n",
    "df.loc[:,numeric_labels] = preprocessing.scale(df.loc[:,numeric_labels])\n",
    "#first five observations\n",
    "df.iloc[:,:-1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3cXJ7HEOE53"
   },
   "source": [
    "We plot the histogram here, to identify the effect of standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nVwP_K-6NEY2"
   },
   "outputs": [],
   "source": [
    "#histogram of numerical variables\n",
    "plt.subplots_adjust(hspace=1)\n",
    " \n",
    "plt.subplot(3, 2, 1)\n",
    "plt.hist(df['Entrance Rank'], ec='black', bins=20)\n",
    "plt.title(\"Entrance Rank\")\n",
    " \n",
    "plt.subplot(3, 2, 2)\n",
    "plt.hist(df['Matriculation'], ec='black', bins=20)\n",
    "plt.title('Matriculation')\n",
    " \n",
    "plt.subplot(3, 2, 3)\n",
    "plt.hist(df['Family Income'], ec='black', bins=20)\n",
    "plt.title('Family Income')\n",
    " \n",
    "plt.subplot(3, 2, 4)\n",
    "plt.hist(df['Physics'], ec='black', bins=20)\n",
    "plt.title('Physics')\n",
    " \n",
    "plt.subplot(3, 2, 5)\n",
    "plt.hist(df['Chemistry'], ec='black', bins=20)\n",
    "plt.title('Chemistry')\n",
    " \n",
    "plt.subplot(3, 2, 6)\n",
    "plt.hist(df['Maths'], ec='black', bins=20)\n",
    "plt.title('Maths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuzzegzKOQuk"
   },
   "source": [
    "We have implemented standardization for all our numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sVhZ3iXcOTB3"
   },
   "source": [
    "**Standardization vs Normalization**\n",
    "The rule of thumb for choosing which method to use for data scaling is:\n",
    "\n",
    "Normalize when the variables have different units.\n",
    "Standardize when a variable has a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl9pHuKaO0Lx"
   },
   "source": [
    "## Categorical Variable Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maHS4a1qO9lX"
   },
   "source": [
    "**One hot encoding**\n",
    "\n",
    "Many machine learning algorithms cannot work with categorical data directly. They need to be converted to numerical representation before processing.\n",
    "\n",
    "Each possible label for the categorical variable is converted into dummy/indicator variables. These dummy variables (of the categorical variable) are assigned values 0 except for one of them is given value 1, corresponding to the category it belongs.\n",
    "\n",
    "Take an example of encoding the categorical variable SeatType. It is having 9 different categories or labels. So nine dummy variable dataframe is created, each having one category label as its name. Every row will be having only one 1, while all others be 0.\n",
    "\n",
    "Then the original categorical variable in the data set is replaced with new encoded dummy/indicator variables. While replacing, one dummy variable is omitted intentionally to avoid collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EkTnuZnMPD2V"
   },
   "outputs": [],
   "source": [
    "#one hot encoding - all categorical variables at once\n",
    "# creating dummy variables to convert categorical into numeric values\n",
    "dummies = pd.get_dummies(df[categoric_labels], prefix= categoric_labels, drop_first=True)\n",
    "df.drop(categoric_labels, axis=1, inplace = True)\n",
    "df = pd.concat([df, dummies], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvwvQTEPPPJv"
   },
   "source": [
    "Observe the one hot encoded categorical variables. For each category except for one, a new variable is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCs2E5dMPuvI"
   },
   "source": [
    "**Summary**\n",
    "\n",
    "Log => (LogTransformer?, PowerTransformer, )\n",
    "Scaling => (MaxAbsScaler, MinMaxScaler, RobustScalar, StandardScalar)\n",
    "One-hot encoding => (OneHotEncoder / get_dummies)\n",
    "Binarize / Bin => Numerical thresholding (Binarizer, KBinsDiscretizer)\n",
    "Normalization => (Normalizer) — full row has unit norm\n",
    "Sklearn preprocessing Functions vs Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkhRWE65Pxf3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNAiotIkyFh1eqUuk/iRvaL",
   "name": "Data Transformations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
